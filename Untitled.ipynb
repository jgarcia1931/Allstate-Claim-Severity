{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Engineer Nanodegree\n",
    "## Allstate Insurance Capstone Proposal\n",
    "Jose Manuel Garcia  \n",
    "December 31st, 2050\n",
    "\n",
    "Allstate Claim Severity Predictive Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Domain Background\n",
    "\n",
    "Allstate is on the largest personal insurance companies in the United states and protect millions of people from potentials damages. When car accidents happen or when other unexpected disasters occur it is a huge relief knowing you are cover by some type of insurance. Recent my girlfriend was involved in a car accident that almost totaled her car. Although she escaped with no bodily injuries her car had thousands of dollars in damages. Luckily, she has full coverage insurance and was able to get all repairs paid for and a rental car without paying anything out of pocket. This event peaked my interest in the insurance business which lead me to this project. Although for this particular instance the insurance claim process was easy and straight forward it is not always the case. This is why Allstate is currently developing automated methods of predicting the cost, and hence severity, of claims. This project will provide insight into better ways to predict claims severity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Statement\n",
    "\n",
    "Allstate is attempting to improve its customer experience by automating methods of predicting the severity of the claim. For this project Allstate provides all data points necessary for predicting the severity of the claim."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets and Inputs\n",
    "\n",
    "All states provides a train and test data set for its Claim Severity competition. Both the training and testing data sets from with many parameters that are used to determine the severity of the claim and the training set also has the includes the loss value of the claim."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution Statement\n",
    "\n",
    "\n",
    "The data set will be evaluated thoroughly in order to get an idea of which supervised learning technique would be best for this particular case. There is many data points that are provided so the first thing that will need to be done is to figure out which data points are relevant to the severity of the claim. The next step would then be to tune the parameters of the supervised learner to get the best possible solutions that does not over fit the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark Model\n",
    "\n",
    "For this project Allstate provides a training set that has the actual value of the claim severity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Metrics\n",
    "\n",
    "The evaluation metric that will be used for this project is the R2 score. The R2 score is the proportion of variance in the dependent variable that is predictable from the independent variable. An R2 score of 0 means that the dependent variable cannot be predicted from the independent variable. An R2 score of 1 means that the dependent variable can be predicted from the independent variable. The ideal model should have and R2 score of 1 but the objective will be to get it as close to 1 as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project Design\n",
    "\n",
    "A big part of machine learning is acquiring the data to build you model and making sure it is clean and reliable. For this project Allstate has already done most of this work by providing all of the data for this Kaggle competition. The next step will be to process the data so that it be used by classifiers in scikit learn. The classifiers in scikit learn require data to be in number format so all letters will need to be converted in to numbers or hot keys. Some of the data is number format and will need to be normalized so that it can be processed and visualized better. After the data is processed a classifier will be used to train the model. Once a classifier is chosen the parameters of the classifier will be tuned until we get the best possible model.\n",
    "\n",
    "https://www.kaggle.com/c/allstate-claims-severity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
